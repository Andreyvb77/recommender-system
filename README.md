# Построение прототипа книжного рекомендательного сервиса
Проект посвящён построению и сравнению рекомендательных моделей для книг на основе открытого датасета Goodreads, 
включающего оценки пользователей, метаданные книг и пользовательские теги.

## Этап 1: Знакомство с данными и EDA (Exploratory Data Analysis)
Произведена загрузка и проверка целостности данных:
ratings (981 756 оценок), books (10 000 книг), tags (34 252 тега), book_tags (999 912 связей).

Анализ распределения оценок показал сильное позитивное смещение:
средняя оценка — 3.86, 66.2% — оценки 4 и 5.
Анализ активности пользователей:
39.2% пользователей поставили ≤5 оценок → проблема холодного старта для пользователей.
Анализ популярности книг выявил искусственную фильтрацию:
все книги имеют от 8 до 100 оценок, медиана = 100 → устранён «длинный хвост», но сохранён холодный старт для книг с 8–20 оценками.
Топ-теги: to-read (140 млн), currently-reading, favorites → доминируют поведенческие маркеры, а не жанры.

# Этап 2: Базовые и контентные модели
Popularity-based: рекомендация книг с высоким средним рейтингом и достаточным числом оценок (≥20). Простая, но не персонализированная.
Content-based: построена TF-IDF-модель на основе объединённого профиля книги — название + теги.
Перед векторизацией проведена очистка:
заполнены пропуски в original_title → title,
исключены/объединены синонимы (sci-fi ↔ science-fiction, favorites ↔ favourites).
Несмотря на это, модель оказалась слабой из-за доминирования поведенческих тегов.

# Этап 3: Коллаборативная фильтрация (CF)
Реализована Item-Based Collaborative Filtering:
построена разреженная матрица пользователь × книга,
сходство между книгами вычислялось через косинусную меру по векторам оценок,
предсказание — взвешенное среднее по K = 20 наиболее похожих книг.
Модель оказалась наиболее эффективной благодаря использованию реальных поведенческих паттернов.

# Этап 4: Матричные разложения (Matrix Factorization)
Обучена модель SVD (из библиотеки scikit-surprise) с гиперпараметрами:
n_factors=300, n_epochs=50, lr=0.004, reg=0.01.
Для корректной работы потребовалось понижение версии numpy < 2.0 из-за несовместимости с surprise.
Несмотря на теоретическую мощность, SVD показала низкое качество — вероятно, из-за сильной разреженности матрицы и отсутствия тонкой настройки.

# Этап 5: Оценка и сравнение моделей
Модели оценивались по метрикам на hold-out тесте (20% оценок, релевантность = rating ≥ 4):
Popularity, Content-based, ItemCF, SVD

# Этап 6: Гибридизация и выводы
Основной вывод: поведенческие методы (ItemCF) значительно эффективнее контентных в условиях данного датасета.
Проблема холодного старта остаётся ключевым ограничением:
для новых книг → использовать очищенные content-based признаки (жанры, автор, название),
для новых пользователей → начинать с популярных книг, затем переключаться на content-based по мере сбора оценок.
Пути улучшения:
Замена TF-IDF на семантические эмбеддинги (Sentence-BERT),
Внедрение гибридных моделей (например, LightFM),
Добавление признаков пользователей и книг (язык, год, автор).
